Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[11:53:24.452518] Namespace(seed=0, debug='', repeat_thresh=0.001, n_fed_cats=-1, detic_path=PosixPath('/path/to/file'), pos_thresh=0.5, aa_expand='scratch', single_dec='naive', head_dim=128, backbone='esm2_t33_650M_UR50D', finetune_backbone='/scratch/cluster/jozhang/models/openfold_params/finetuning_ptm_2.pt', freeze_at=14, model='esm2_all_chemical_features', data_dir='05_datasets', eval_only_data_path=None, n_msa_seqs=128, n_extra_msa_seqs=1024, af_extract_feat='both', max_context_length=2000, num_workers=10, epochs=20, batch_size=8, lr=0.0003, min_lr=1e-09, weight_decay=0.5, warmup_epochs=10, cross_eval_kfold=None, lambda_single=0.1, loss_single_aug='none', lambda_double=1.0, double_subsample_destabilizing_ratio=8, lambda_pos=4, eval=False, dist_eval=False, eval_reverse=False, test=False, finetune='', resume='', start_epoch=0, save_pred_dict=False, eval_period=5, save_period=10, disable_wandb=False, model_checkpoint_path=None, device='cpu', world_size=1, name_to_x='../out_data/colabfold_name_to_x.pt', local_rank=-1, dist_on_itp=False, dist_url='env://', contrastive_output=True, output_dir=PosixPath('../model_results/esm2_all_chemical_features_05_datasets'), distributed=False)
[11:53:25.339315] ESMallChemicalFeatures(
  (esm): EsmModel(
    (embeddings): EsmEmbeddings(
      (word_embeddings): Embedding(33, 1280, padding_idx=1)
      (dropout): Dropout(p=0.0, inplace=False)
      (position_embeddings): Embedding(1026, 1280, padding_idx=1)
    )
    (encoder): EsmEncoder(
      (layer): ModuleList(
        (0-32): 33 x EsmLayer(
          (attention): EsmAttention(
            (self): EsmSelfAttention(
              (query): Linear(in_features=1280, out_features=1280, bias=True)
              (key): Linear(in_features=1280, out_features=1280, bias=True)
              (value): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (rotary_embeddings): RotaryEmbedding()
            )
            (output): EsmSelfOutput(
              (dense): Linear(in_features=1280, out_features=1280, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
          (intermediate): EsmIntermediate(
            (dense): Linear(in_features=1280, out_features=5120, bias=True)
          )
          (output): EsmOutput(
            (dense): Linear(in_features=5120, out_features=1280, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    )
    (pooler): EsmPooler(
      (dense): Linear(in_features=1280, out_features=1280, bias=True)
      (activation): Tanh()
    )
    (contact_head): EsmContactPredictionHead(
      (regression): Linear(in_features=660, out_features=1, bias=True)
      (activation): Sigmoid()
    )
  )
  (film): FiLMWithConcatenation(
    (chemical_proj): Sequential(
      (0): Linear(in_features=3, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=1280, bias=True)
      (3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    )
    (film_layer): Linear(in_features=2560, out_features=2560, bias=True)
    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=1280, out_features=640, bias=True)
    (1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=640, out_features=3, bias=True)
  )
  (criterion): CrossEntropyLoss()
)
[11:53:25.340641] Training 68,143,000 of 659,821,720 parameters
[11:53:25.364822] len(ds_test)=268
[11:53:25.413977] len(ds_train)=1071
[11:53:25.414042] Start training for 20 epochs, saving to ../model_results/esm2_all_chemical_features_05_datasets
Traceback (most recent call last):
  File "/Users/briansu/workspace/mamp_prediction_ml/06_scripts_ml/06_main_train.py", line 650, in <module>
    main(args)
  File "/Users/briansu/workspace/mamp_prediction_ml/06_scripts_ml/06_main_train.py", line 509, in main
    evaluate(model, dl_test, device, args, args.output_dir)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/Users/briansu/workspace/mamp_prediction_ml/06_scripts_ml/engine_train.py", line 232, in evaluate
    output = model(batch['x'])
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/briansu/workspace/mamp_prediction_ml/06_scripts_ml/models/esm_all_chemical_features.py", line 140, in forward
    outputs = self.esm(
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/transformers/models/esm/modeling_esm.py", line 907, in forward
    encoder_outputs = self.encoder(
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/transformers/models/esm/modeling_esm.py", line 612, in forward
    layer_outputs = layer_module(
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/transformers/models/esm/modeling_esm.py", line 502, in forward
    self_attention_outputs = self.attention(
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/transformers/models/esm/modeling_esm.py", line 436, in forward
    self_outputs = self.self(
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/briansu/anaconda3/envs/esmfold/lib/python3.9/site-packages/transformers/models/esm/modeling_esm.py", line 360, in forward
    attention_scores = attention_scores + attention_mask
KeyboardInterrupt
[11:53:49.287941] Test:  [ 0/34]  eta: 0:13:31    time: 23.8699  data: 0.0146